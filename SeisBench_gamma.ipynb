{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Ignoring invalid distribution -umpy (/scicore/home/dokman0000/shi0000/anaconda3/envs/newtorch/lib/python3.10/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Error parsing dependencies of gym: Expected matching RIGHT_PARENTHESIS for LEFT_PARENTHESIS, after version specifier\n",
      "    opencv-python (>=3.) ; extra == 'all'\n",
      "                  ~~~~^\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -umpy (/scicore/home/dokman0000/shi0000/anaconda3/envs/newtorch/lib/python3.10/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -umpy (/scicore/home/dokman0000/shi0000/anaconda3/envs/newtorch/lib/python3.10/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install -q scikit-learn pyproj seaborn pandas seisbench pyproj obspy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Ignoring invalid distribution -umpy (/scicore/home/dokman0000/shi0000/anaconda3/envs/newtorch/lib/python3.10/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Error parsing dependencies of gym: Expected matching RIGHT_PARENTHESIS for LEFT_PARENTHESIS, after version specifier\n",
      "    opencv-python (>=3.) ; extra == 'all'\n",
      "                  ~~~~^\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -umpy (/scicore/home/dokman0000/shi0000/anaconda3/envs/newtorch/lib/python3.10/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -umpy (/scicore/home/dokman0000/shi0000/anaconda3/envs/newtorch/lib/python3.10/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip -q install pyocto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    import obspy\n",
    "    obspy.read()\n",
    "except TypeError:\n",
    "    # Needs to restart the runtime once, because obspy only works properly after restart.\n",
    "    print('Stopping RUNTIME. If you run this code for the first time, this is expected. Colaboratory will restart automatically. Please run again.')\n",
    "    exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import obspy\n",
    "from obspy.clients.fdsn import Client\n",
    "from obspy import UTCDateTime\n",
    "from pyproj import CRS, Transformer\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import torch\n",
    "#pd.set_option('future.no_silent_downcasting', True)\n",
    "import seisbench.models as sbm\n",
    "\n",
    "sns.set(font_scale=1.2)\n",
    "sns.set_style(\"ticks\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Projections\n",
    "wgs84 = CRS.from_epsg(4326)\n",
    "local_crs = CRS.from_epsg(9155)  # SIRGAS-Chile 2016 / UTM zone 19S\n",
    "transformer = Transformer.from_crs(wgs84, local_crs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = Client(\"GFZ\")\n",
    "\n",
    "t0 = UTCDateTime(\"2014/05/01 00:00:00\")\n",
    "t1 = t0 + 12 * 60 * 60\n",
    "# t1 = t0 + 24 * 60 * 60   # Full day, requires more memory\n",
    "stream = client.get_waveforms(network=\"CX\", station=\"*\", location=\"*\", channel=\"HH?\", starttime=t0, endtime=t1)\n",
    "\n",
    "inv = client.get_stations(network=\"CX\", station=\"*\", location=\"*\", channel=\"HH?\", starttime=t0, endtime=t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "config={}\n",
    "config[\"dims\"] = ['x(km)', 'y(km)', 'z(km)']\n",
    "config[\"use_dbscan\"] = True\n",
    "config[\"x(km)\"] = (250, 600)\n",
    "config[\"y(km)\"] = (7200, 8000)\n",
    "config[\"vel\"] = {\"P\": 7.0, \"S\": 7.0 / 1.75} \n",
    "config[\"z(km)\"] = (0, 200)\n",
    "\n",
    "config[\"vel\"] = {\"p\": 7.0, \"s\": 7.0 / 1.75}  # We assume rather high velocities as we expect deeper events\n",
    "config[\"method\"] = \"BGMM\"\n",
    "if config[\"method\"] == \"BGMM\":\n",
    "    config[\"oversample_factor\"] = 4\n",
    "if config[\"method\"] == \"GMM\":\n",
    "    config[\"oversample_factor\"] = 1\n",
    "\n",
    "# DBSCAN\n",
    "config[\"bfgs_bounds\"] = (\n",
    "    (config[\"x(km)\"][0] - 1, config[\"x(km)\"][1] + 1),  # x\n",
    "    (config[\"y(km)\"][0] - 1, config[\"y(km)\"][1] + 1),  # y\n",
    "    (0, config[\"z(km)\"][1] + 1),  # x\n",
    "    (None, None),  # t\n",
    ")\n",
    "config[\"dbscan_eps\"] = 25  # seconds\n",
    "config[\"dbscan_min_samples\"] = 3\n",
    "\n",
    "# Filtering\n",
    "config[\"min_picks_per_eq\"] = 10\n",
    "\n",
    "config['min_p_picks_per_eq']=4\n",
    "config['min_s_picks_per_eq']=4\n",
    "config[\"max_sigma11\"] = 2.0\n",
    "config[\"max_sigma22\"] = 1.0\n",
    "config[\"max_sigma12\"] = 1.0\n",
    "config[\"use_amplitude\"]=False\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-16 01:06:37,914 | seisbench | WARNING | Setting remote root to: https://seisbench.gfz-potsdam.de/mirror/\n",
      "Please note that this can affect your download speed.\n"
     ]
    }
   ],
   "source": [
    "import seisbench\n",
    "import torch\n",
    "torch.set_num_threads(1)\n",
    "seisbench.use_backup_repository()\n",
    "picker = sbm.PhaseNet.from_pretrained(\"instance\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "Numba needs NumPy 1.24 or less",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [16], line 39\u001b[0m\n\u001b[1;32m     35\u001b[0m northing \u001b[38;5;241m=\u001b[39m {station: y \u001b[38;5;28;01mfor\u001b[39;00m station, y \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(station_df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m\"\u001b[39m], station_df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my(km)\u001b[39m\u001b[38;5;124m\"\u001b[39m])}\n\u001b[1;32m     36\u001b[0m station_dict \u001b[38;5;241m=\u001b[39m {station: (x, y) \u001b[38;5;28;01mfor\u001b[39;00m station, x, y \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(station_df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m\"\u001b[39m], station_df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mx(km)\u001b[39m\u001b[38;5;124m\"\u001b[39m], station_df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my(km)\u001b[39m\u001b[38;5;124m\"\u001b[39m])}\n\u001b[0;32m---> 39\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgamma\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m association\n\u001b[1;32m     41\u001b[0m catalogs, assignments \u001b[38;5;241m=\u001b[39m association(pick_df, station_df, config, method\u001b[38;5;241m=\u001b[39mconfig[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmethod\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m     43\u001b[0m catalog \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(catalogs)\n",
      "File \u001b[0;32m~/anaconda3/envs/newtorch/lib/python3.10/site-packages/gamma/__init__.py:5\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;124;03mThe :mod:`sklearn.mixture` module implements mixture modeling algorithms.\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_gaussian_mixture\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m GaussianMixture\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_bayesian_mixture\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BayesianGaussianMixture\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# from .seismic_ops import *\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/newtorch/lib/python3.10/site-packages/gamma/_gaussian_mixture.py:13\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mextmath\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m row_norms\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mvalidation\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _deprecate_positional_args\n\u001b[0;32m---> 13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mseismic_ops\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_base\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BaseMixture, _check_shape\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m###############################################################################\u001b[39;00m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m# Gaussian mixture shape checkers used by the GaussianMixture class\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/newtorch/lib/python3.10/site-packages/gamma/seismic_ops.py:7\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01moptimize\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnumba\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m njit\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnumba\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtyped\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m List\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# import shelve\u001b[39;00m\n\u001b[1;32m     11\u001b[0m \n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m###################################### Eikonal Solver ######################################\u001b[39;00m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# |\\nabla u| = f\u001b[39;00m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# ((u - a1)^+)^2 + ((u - a2)^+)^2 + ((u - a3)^+)^2 = f^2 h^2\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/newtorch/lib/python3.10/site-packages/numba/__init__.py:55\u001b[0m\n\u001b[1;32m     50\u001b[0m             msg \u001b[38;5;241m=\u001b[39m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNumba requires SciPy version 1.0 or greater. Got SciPy \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     51\u001b[0m                    \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mscipy\u001b[38;5;241m.\u001b[39m__version__\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     52\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(msg)\n\u001b[0;32m---> 55\u001b[0m \u001b[43m_ensure_critical_deps\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;66;03m# END DO NOT MOVE\u001b[39;00m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;66;03m# ---------------------- WARNING WARNING WARNING ----------------------------\u001b[39;00m\n\u001b[1;32m     60\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_version\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m get_versions\n",
      "File \u001b[0;32m~/anaconda3/envs/newtorch/lib/python3.10/site-packages/numba/__init__.py:42\u001b[0m, in \u001b[0;36m_ensure_critical_deps\u001b[0;34m()\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(msg)\n\u001b[1;32m     41\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m numpy_version \u001b[38;5;241m>\u001b[39m (\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m24\u001b[39m):\n\u001b[0;32m---> 42\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNumba needs NumPy 1.24 or less\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     43\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     44\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m\n",
      "\u001b[0;31mImportError\u001b[0m: Numba needs NumPy 1.24 or less"
     ]
    }
   ],
   "source": [
    "npicks_list=[]\n",
    "harparesults_list=[]\n",
    "for r in [1,0.5,0.1,0.05,0.01]:\n",
    "    picks = picker.classify(stream, batch_size=256, P_threshold=0.075*r, S_threshold=0.1*r).picks\n",
    "      # Output number of P and S picks\n",
    "    npicks_list.append(len(picks))\n",
    "    pick_df = []\n",
    "    for p in picks:\n",
    "        pick_df.append({\n",
    "            \"id\": p.trace_id,\n",
    "            \"timestamp\": p.peak_time.datetime,\n",
    "            \"prob\": p.peak_value,\n",
    "            \"type\": p.phase.lower()\n",
    "        })\n",
    "    pick_df = pd.DataFrame(pick_df)\n",
    "\n",
    "    station_df = []\n",
    "    for station in inv[0]:\n",
    "        station_df.append({\n",
    "            \"id\": f\"CX.{station.code}.\",\n",
    "            \"longitude\": station.longitude,\n",
    "            \"latitude\": station.latitude,\n",
    "            \"elevation(m)\": station.elevation\n",
    "        })\n",
    "    station_df = pd.DataFrame(station_df)\n",
    "\n",
    "    station_df[\"x(km)\"] = station_df.apply(lambda x: transformer.transform(x[\"latitude\"], x[\"longitude\"])[0] / 1e3, axis=1)\n",
    "    station_df[\"y(km)\"] = station_df.apply(lambda x: transformer.transform(x[\"latitude\"], x[\"longitude\"])[1] / 1e3, axis=1)\n",
    "    station_df[\"z(km)\"] = - station_df[\"elevation(m)\"] / 1e3\n",
    "\n",
    "    station_df[\"x(km)\"] = station_df.apply(lambda x: transformer.transform(x[\"latitude\"], x[\"longitude\"])[0] / 1e3, axis=1)\n",
    "    station_df[\"y(km)\"] = station_df.apply(lambda x: transformer.transform(x[\"latitude\"], x[\"longitude\"])[1] / 1e3, axis=1)\n",
    "    station_df[\"z(km)\"] = - station_df[\"elevation(m)\"] / 1e3\n",
    "\n",
    "    northing = {station: y for station, y in zip(station_df[\"id\"], station_df[\"y(km)\"])}\n",
    "    station_dict = {station: (x, y) for station, x, y in zip(station_df[\"id\"], station_df[\"x(km)\"], station_df[\"y(km)\"])}\n",
    "    \n",
    "    \n",
    "    from gamma.utils import association\n",
    "\n",
    "    catalogs, assignments = association(pick_df, station_df, config, method=config[\"method\"])\n",
    "\n",
    "    catalog = pd.DataFrame(catalogs)\n",
    "    assignments = pd.DataFrame(assignments, columns=[\"pick_idx\", \"event_idx\", \"prob_gamma\"])\n",
    "\n",
    "\n",
    "    harparesults_list.append(len(catalog))\n",
    "    print(r,len(picks),len(catalog),Counter([p.phase for p in picks]))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Ignoring invalid distribution -umpy (/scicore/home/dokman0000/shi0000/anaconda3/envs/newtorch/lib/python3.10/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: numba in /scicore/home/dokman0000/shi0000/anaconda3/envs/newtorch/lib/python3.10/site-packages (0.57.0)\n",
      "Collecting numba\n",
      "  Downloading numba-0.60.0-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.7 kB)\n",
      "Collecting llvmlite<0.44,>=0.43.0dev0 (from numba)\n",
      "  Downloading llvmlite-0.43.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.8 kB)\n",
      "Requirement already satisfied: numpy<2.1,>=1.22 in /scicore/home/dokman0000/shi0000/anaconda3/envs/newtorch/lib/python3.10/site-packages (from numba) (1.26.4)\n",
      "Downloading numba-0.60.0-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (3.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.7/3.7 MB\u001b[0m \u001b[31m37.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading llvmlite-0.43.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (43.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.9/43.9 MB\u001b[0m \u001b[31m53.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25h\u001b[33mWARNING: Error parsing dependencies of gym: Expected matching RIGHT_PARENTHESIS for LEFT_PARENTHESIS, after version specifier\n",
      "    opencv-python (>=3.) ; extra == 'all'\n",
      "                  ~~~~^\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -umpy (/scicore/home/dokman0000/shi0000/anaconda3/envs/newtorch/lib/python3.10/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mInstalling collected packages: llvmlite, numba\n",
      "  Attempting uninstall: llvmlite\n",
      "    Found existing installation: llvmlite 0.40.1rc1\n",
      "    Uninstalling llvmlite-0.40.1rc1:\n",
      "      Successfully uninstalled llvmlite-0.40.1rc1\n",
      "  Attempting uninstall: numba\n",
      "    Found existing installation: numba 0.57.0\n",
      "    Uninstalling numba-0.57.0:\n",
      "      Successfully uninstalled numba-0.57.0\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -umpy (/scicore/home/dokman0000/shi0000/anaconda3/envs/newtorch/lib/python3.10/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mSuccessfully installed llvmlite-0.43.0 numba-0.60.0\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade numba"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Associating 249 clusters with 32 CPUs\n",
      "................................................................................................................................................................................\n",
      "Associated 100 events\n",
      ".........................................................................1 7399 191 Counter({'P': 4903, 'S': 2496})\n"
     ]
    }
   ],
   "source": [
    "from gamma.utils import association\n",
    "\n",
    "catalogs, assignments = association(pick_df, station_df, config, method=config[\"method\"])\n",
    "\n",
    "catalog = pd.DataFrame(catalogs)\n",
    "assignments = pd.DataFrame(assignments, columns=[\"pick_idx\", \"event_idx\", \"prob_gamma\"])\n",
    "\n",
    "\n",
    "harparesults_list.append(len(catalog))\n",
    "print(r,len(picks),len(catalog),Counter([p.phase for p in picks]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dims': ['x(km)', 'y(km)', 'z(km)'],\n",
       " 'use_dbscan': True,\n",
       " 'x(km)': (250, 600),\n",
       " 'y(km)': (7200, 8000),\n",
       " 'vel': {'p': 7.0, 's': 4.0},\n",
       " 'z(km)': (0, 200),\n",
       " 'method': 'BGMM',\n",
       " 'oversample_factor': 4,\n",
       " 'bfgs_bounds': ((249, 601), (7199, 8001), (0, 201), (None, None)),\n",
       " 'dbscan_eps': 25,\n",
       " 'dbscan_min_samples': 3,\n",
       " 'min_picks_per_eq': 5,\n",
       " 'max_sigma11': 2.0,\n",
       " 'max_sigma22': 1.0,\n",
       " 'max_sigma12': 1.0,\n",
       " 'use_amplitude': False,\n",
       " 'eikonal': None,\n",
       " 'ncpu': 32}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 5/25 [00:32<02:03,  6.19s/it]"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pickle\n",
    "\n",
    "# with open('pick_df.pkl', 'wb') as f:\n",
    "#     pickle.dump(pick_df, f)\n",
    "    \n",
    "# with open('station_df.pkl', 'wb') as f:\n",
    "#     pickle.dump(station_df, f)\n",
    "# with open('config.pkl', 'wb') as f:\n",
    "#     pickle.dump(config, f)\n",
    "    \n",
    "    \n",
    "# import pickle\n",
    "\n",
    "# # Load pick_df\n",
    "# with open('pick_df.pkl', 'rb') as f:\n",
    "#     pick_df = pickle.load(f)\n",
    "\n",
    "# # Load station_df\n",
    "# with open('station_df.pkl', 'rb') as f:\n",
    "#     station_df = pickle.load(f)\n",
    "\n",
    "# # Load config\n",
    "# with open('config.pkl', 'rb') as f:\n",
    "#     config = pickle.load(f)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "newtorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
